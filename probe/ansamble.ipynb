{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7cf6aa0-eb13-419f-8244-7f03e4602192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "train_df = pd.read_csv('train/train_df.csv')\n",
    "test_df = pd.read_csv('test/test_df.csv')\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd977dcd-a707-439e-9de6-257260b012fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(['search_id', 'target'], axis=1)\n",
    "y_train = train_df['target']\n",
    "X_test = test_df.drop(['search_id', 'target'], axis=1)\n",
    "y_test = test_df['target']\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aab0e08-5c74-4e7b-b015-3730d6e30ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, average_precision_score\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate(model, testing_set_x, testing_set_y):\n",
    "    # Получение предсказанных вероятностей для положительного класса\n",
    "    predictions_proba = model.predict(testing_set_x)\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    accuracy = accuracy_score(testing_set_y, predictions_proba >= 0.5)\n",
    "    roc_auc = roc_auc_score(testing_set_y, predictions_proba)\n",
    "    precision = precision_score(testing_set_y, predictions_proba >= 0.5)\n",
    "    recall = recall_score(testing_set_y, predictions_proba >= 0.5)\n",
    "    pr_auc = average_precision_score(testing_set_y, predictions_proba)\n",
    "    \n",
    "    # Формирование результата\n",
    "    result = pd.DataFrame([[accuracy, precision, recall, roc_auc, pr_auc]], columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc', 'PR_auc'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7afeb77-26df-4e31-88ae-b7b51a2c8a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's binary_logloss: 0.305711\tvalid_0's auc: 0.725428\n",
      "{'valid_0': OrderedDict([('binary_logloss', [0.6455847351171102, 0.6067440196583501, 0.5695335677496439, 0.5391916555692454, 0.5128062948576435, 0.4859830400044182, 0.4609022804831424, 0.4439248933006247, 0.42810114210546807, 0.4062344196969009, 0.390494954289057, 0.3745143461192054, 0.3575094401146548, 0.3418940980426408, 0.3305702348530008, 0.31706559872354695, 0.3057112719653844, 0.29266489457428607, 0.28217412049342017, 0.2738487731538682, 0.26874582096111027, 0.2604089153935214, 0.2519222113548596, 0.2443139000433738, 0.23739611022771712, 0.2313598240168327, 0.22672161352919237]), ('auc', [0.5156993901239425, 0.5643320873499902, 0.5914814086169585, 0.663623844186504, 0.6697816250245918, 0.6653452685421994, 0.685638402518198, 0.6865040330513477, 0.6896419437340153, 0.690537084398977, 0.6954456029903601, 0.7014361597481802, 0.7059512099154043, 0.7087743458587449, 0.7221719457013575, 0.7200177060790871, 0.7254278969112729, 0.725408223490065, 0.7214145189848514, 0.7153551052528034, 0.7153157584103875, 0.7158469407830022, 0.714755065905961, 0.7171552232933307, 0.7138500885303954, 0.716289592760181, 0.7134467833956325])])}\n",
      "   Accuracy  Precision    Recall   ROC_auc    PR_auc\n",
      "0  0.962067      0.125  0.117647  0.725428  0.071871\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "# Предполагается, что X и y уже определены в вашем наборе данных\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание ансамбля из 10 случайных лесов\n",
    "ensemble = [RandomForestClassifier(n_estimators=100, random_state=42+i) for i in range(10)]\n",
    "\n",
    "# Обучение каждой модели-члена на подмножестве данных\n",
    "for i, model in enumerate(ensemble):\n",
    "    # Генерация индексов подмножества с заменой\n",
    "    sample_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_subset, y_subset = X_train[sample_indices], y_train[sample_indices]\n",
    "    model.fit(X_subset, y_subset)\n",
    "    print(f\"Модель {i+1} обучена.\")\n",
    "\n",
    "# Совместное предсказание всех моделей ансамбля\n",
    "predictions = np.array([model.predict(X_test) for model in ensemble])\n",
    "\n",
    "# Использование моды для определения окончательных предсказаний ансамбля\n",
    "ensemble_predictions = mode(predictions, axis=0)[0][0]\n",
    "\n",
    "# Оценка точности ансамбля\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(f\"Точность ансамбля: {ensemble_accuracy}\")\n",
    "print(evals_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73b77b93-8012-4da1-a591-dbef80c609b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6552c021-a8ac-4f85-8961-d6044b41b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.4875445357641325\n"
     ]
    }
   ],
   "source": [
    "# Мы могли бы группировать данные по search_id и рассчитывать NDCG для каждой группы,\n",
    "# но поскольку задача стоит рассчитать NDCG для всех документов, мы рассчитаем её глобально.\n",
    "ndcg_score = ndcg_score([y_test], [y_pred], k=None)\n",
    "print(f'NDCG Score: {ndcg_score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
